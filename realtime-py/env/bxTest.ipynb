{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-13T12:50:30.480080Z",
     "start_time": "2025-02-13T12:50:00.042743Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -q scikit-learn==1.4 && pip install -q --no-deps scikeras"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in d:\\python\\lib\\site-packages (24.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 6.3 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: To modify pip, please run the following command:\n",
      "D:\\PyThon\\python.exe -m pip install --upgrade pip\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\PyThon\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\PyThon\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\PyThon\\Lib\\site-packages\\~klearn'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikeras 0.13.0 requires scikit-learn>=1.4.2, but you have scikit-learn 1.4.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:51:19.530378Z",
     "start_time": "2025-02-13T12:51:19.526804Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('data/bx/op/com'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "id": "389d03d7cd8854d8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:51:26.542375Z",
     "start_time": "2025-02-13T12:51:25.960915Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "train = pd.read_csv(r'D:\\mmmm\\pycharmM\\apr17\\data\\bx\\op\\com\\train.csv')\n",
    "test = pd.read_csv(r'D:\\mmmm\\pycharmM\\apr17\\data\\bx\\op\\com\\test.csv')\n",
    "original = pd.read_csv(r'D:\\mmmm\\pycharmM\\apr17\\data\\bx\\op\\com\\train.csv')"
   ],
   "id": "495e3c3ae27f114b",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:51:31.607911Z",
     "start_time": "2025-02-13T12:51:31.190812Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "train = pd.concat([train, original]).reset_index(drop=True) \n",
    "train = train.drop_duplicates(keep=\"last\").reset_index(drop=True)\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print('Size of train dataset: {} ____ Size of test dataset: {}'.format(train.shape,test.shape))"
   ],
   "id": "ea0a8bb1102abbb2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset: (381109, 12) ____ Size of test dataset: (127037, 11)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:51:35.273921Z",
     "start_time": "2025-02-13T12:51:35.156961Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define column\n",
    "less = []\n",
    "for i in train.columns[1:]:\n",
    "    if train[i].nunique() < 10:\n",
    "        less.append(i)\n",
    "        \n",
    "print('Column have LESS than 10 unique values: ', less)\n",
    "print('Column have MORE than 10 unique values: ', [i for i in train.columns if i not in less])\n",
    "\n",
    "for i in less:\n",
    "    train[i] = train[i].astype('category')"
   ],
   "id": "62a99e4b6fa524a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column have LESS than 10 unique values:  ['Gender', 'Driving_License', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Response']\n",
      "Column have MORE than 10 unique values:  ['id', 'Age', 'Region_Code', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:51:39.648573Z",
     "start_time": "2025-02-13T12:51:39.643759Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# Define the new order of categories\n",
    "new_categories = ['< 1 Year', '1-2 Year', '> 2 Years']\n",
    "\n",
    "# Create a new CategoricalDtype with the desired order\n",
    "new_dtype = CategoricalDtype(categories=new_categories, ordered=True)\n",
    "\n",
    "# Update the 'Vehicle_Age' column with the new dtype\n",
    "train['Vehicle_Age'] = train['Vehicle_Age'].astype(new_dtype)"
   ],
   "id": "d7db346037ba06a2",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:51:43.837049Z",
     "start_time": "2025-02-13T12:51:43.806559Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "train['age_bins'] = pd.cut(train['Age'], bins=7)\n",
    "train['Age_Type'] = train['age_bins'].cat.codes\n",
    "train['Age_x_Vehicle_Age'] = train['Age_Type'] * train['Vehicle_Age'].cat.codes\n",
    "train['Age_x_Vehicle_Damage'] = train['Age_Type'] * train['Vehicle_Damage'].cat.codes\n",
    "train['Age_x_Previously_Insured'] = train['Age_Type'] * train['Previously_Insured'].cat.codes\n",
    "train"
   ],
   "id": "69abf972bce2c410",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            id  Gender  Age Driving_License  Region_Code Previously_Insured  \\\n",
       "0       175302  Female   59               1         46.0                  0   \n",
       "1       132243    Male   43               1         28.0                  0   \n",
       "2       284074  Female   27               1          3.0                  1   \n",
       "3       247131    Male   59               1         28.0                  0   \n",
       "4       258841  Female   42               1         28.0                  1   \n",
       "...        ...     ...  ...             ...          ...                ...   \n",
       "381104   59630    Male   71               1          8.0                  0   \n",
       "381105  273228    Male   22               1         15.0                  1   \n",
       "381106  348608    Male   21               1          8.0                  0   \n",
       "381107  268917    Male   46               1         28.0                  0   \n",
       "381108  220747    Male   57               1         27.0                  0   \n",
       "\n",
       "       Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  \\\n",
       "0         1-2 Year             No         40588.0                  11.0   \n",
       "1         1-2 Year            Yes         25844.0                   3.0   \n",
       "2         < 1 Year             No         39036.0                 152.0   \n",
       "3         1-2 Year             No         40964.0                  26.0   \n",
       "4         1-2 Year             No         42538.0                  26.0   \n",
       "...            ...            ...             ...                   ...   \n",
       "381104    1-2 Year            Yes         47261.0                  26.0   \n",
       "381105    < 1 Year             No         31996.0                 152.0   \n",
       "381106    < 1 Year            Yes         33815.0                 160.0   \n",
       "381107   > 2 Years            Yes         35043.0                  55.0   \n",
       "381108    1-2 Year             No          2630.0                 152.0   \n",
       "\n",
       "        Vintage Response          age_bins  Age_Type  Age_x_Vehicle_Age  \\\n",
       "0           209        0  (57.143, 66.429]         4                  4   \n",
       "1           179        1  (38.571, 47.857]         2                  2   \n",
       "2           151        0  (19.935, 29.286]         0                  0   \n",
       "3           161        0  (57.143, 66.429]         4                  4   \n",
       "4           235        0  (38.571, 47.857]         2                  2   \n",
       "...         ...      ...               ...       ...                ...   \n",
       "381104       78        0  (66.429, 75.714]         5                  5   \n",
       "381105      275        0  (19.935, 29.286]         0                  0   \n",
       "381106      190        0  (19.935, 29.286]         0                  0   \n",
       "381107      133        1  (38.571, 47.857]         2                  4   \n",
       "381108      248        0  (47.857, 57.143]         3                  3   \n",
       "\n",
       "        Age_x_Vehicle_Damage  Age_x_Previously_Insured  \n",
       "0                          0                         0  \n",
       "1                          2                         0  \n",
       "2                          0                         0  \n",
       "3                          0                         0  \n",
       "4                          0                         2  \n",
       "...                      ...                       ...  \n",
       "381104                     5                         0  \n",
       "381105                     0                         0  \n",
       "381106                     0                         0  \n",
       "381107                     2                         0  \n",
       "381108                     0                         0  \n",
       "\n",
       "[381109 rows x 17 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "      <th>age_bins</th>\n",
       "      <th>Age_Type</th>\n",
       "      <th>Age_x_Vehicle_Age</th>\n",
       "      <th>Age_x_Vehicle_Damage</th>\n",
       "      <th>Age_x_Previously_Insured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175302</td>\n",
       "      <td>Female</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>40588.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "      <td>(57.143, 66.429]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132243</td>\n",
       "      <td>Male</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>25844.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>(38.571, 47.857]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>284074</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>39036.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>(19.935, 29.286]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>247131</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>40964.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>(57.143, 66.429]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>258841</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>42538.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>(38.571, 47.857]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381104</th>\n",
       "      <td>59630</td>\n",
       "      <td>Male</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>47261.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>(66.429, 75.714]</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381105</th>\n",
       "      <td>273228</td>\n",
       "      <td>Male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>31996.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>(19.935, 29.286]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381106</th>\n",
       "      <td>348608</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>33815.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>(19.935, 29.286]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381107</th>\n",
       "      <td>268917</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>35043.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>(38.571, 47.857]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381108</th>\n",
       "      <td>220747</td>\n",
       "      <td>Male</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>(47.857, 57.143]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>381109 rows × 17 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:51:49.215971Z",
     "start_time": "2025-02-13T12:51:49.197596Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "X = train.drop(['id','Response','age_bins'],axis=1)\n",
    "y = train['Response']"
   ],
   "id": "2ae3dd0a8d8a32c5",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:52:08.830687Z",
     "start_time": "2025-02-13T12:52:08.105047Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder, RobustScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "coltrans = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), ['Gender', 'Vehicle_Damage']),\n",
    "        ('minmax', MinMaxScaler(), ['Age', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Policy_Sales_Channel', 'Vintage']),\n",
    "        ('ordinal', OrdinalEncoder(categories=[['< 1 Year', '1-2 Year', '> 2 Years']]), ['Vehicle_Age']),\n",
    "        ('robust', RobustScaler(), ['Annual_Premium']),\n",
    "        ('standard', StandardScaler(), ['Age_Type', 'Age_x_Vehicle_Age', 'Age_x_Vehicle_Damage', 'Age_x_Previously_Insured'])\n",
    "    ],\n",
    "    remainder='passthrough'  # Keeps columns not specified in transformers\n",
    ")"
   ],
   "id": "c7af97fa2cccfd5a",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'check_pandas_support' from 'sklearn.utils' (D:\\PyThon\\Lib\\site-packages\\sklearn\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompose\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ColumnTransformer\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpipeline\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Pipeline\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mimblearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mover_sampling\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SMOTE\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mimblearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01munder_sampling\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RandomUnderSampler\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m roc_auc_score, classification_report, confusion_matrix\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\imblearn\\__init__.py:52\u001B[0m\n\u001B[0;32m     48\u001B[0m     sys\u001B[38;5;241m.\u001B[39mstderr\u001B[38;5;241m.\u001B[39mwrite(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPartial import of imblearn during the build process.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001B[39;00m\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;66;03m# process, as it may not be compiled yet\u001B[39;00m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     53\u001B[0m         combine,\n\u001B[0;32m     54\u001B[0m         ensemble,\n\u001B[0;32m     55\u001B[0m         exceptions,\n\u001B[0;32m     56\u001B[0m         metrics,\n\u001B[0;32m     57\u001B[0m         over_sampling,\n\u001B[0;32m     58\u001B[0m         pipeline,\n\u001B[0;32m     59\u001B[0m         tensorflow,\n\u001B[0;32m     60\u001B[0m         under_sampling,\n\u001B[0;32m     61\u001B[0m         utils,\n\u001B[0;32m     62\u001B[0m     )\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_version\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FunctionSampler\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03mover-sampling and under-sampling.\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_smote_enn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SMOTEENN\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_smote_tomek\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SMOTETomek\n\u001B[0;32m      8\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSMOTEENN\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSMOTETomek\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m clone\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m check_X_y\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseSampler\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mover_sampling\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SMOTE\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mover_sampling\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseOverSampler\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\imblearn\\base.py:15\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_metadata_requests\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m METHODS\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmulticlass\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m check_classification_targets\n\u001B[1;32m---> 15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m check_sampling_strategy, check_target_type\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_sklearn_compat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _fit_context, get_tags, validate_data\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_validation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ArraysTransformer\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\imblearn\\utils\\__init__.py:6\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03mThe :mod:`imblearn.utils` module includes various utilities.\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_docstring\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Substitution\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_validation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      7\u001B[0m     check_neighbors_object,\n\u001B[0;32m      8\u001B[0m     check_sampling_strategy,\n\u001B[0;32m      9\u001B[0m     check_target_type,\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     12\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcheck_neighbors_object\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcheck_sampling_strategy\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcheck_target_type\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSubstitution\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     17\u001B[0m ]\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\imblearn\\utils\\_validation.py:20\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmulticlass\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m type_of_target\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvalidation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _num_samples\n\u001B[1;32m---> 20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_sklearn_compat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _is_pandas_df, check_array\n\u001B[0;32m     22\u001B[0m SAMPLING_KIND \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mover-sampling\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munder-sampling\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbypass\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     28\u001B[0m )\n\u001B[0;32m     29\u001B[0m TARGET_KIND \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel-indicator\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\imblearn\\utils\\_sklearn_compat.py:370\u001B[0m\n\u001B[0;32m    363\u001B[0m \u001B[38;5;66;03m########################################################################################\u001B[39;00m\n\u001B[0;32m    364\u001B[0m \u001B[38;5;66;03m# Upgrading for scikit-learn 1.6\u001B[39;00m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;66;03m########################################################################################\u001B[39;00m\n\u001B[0;32m    368\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sklearn_version \u001B[38;5;241m<\u001B[39m parse_version(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1.6\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    369\u001B[0m     \u001B[38;5;66;03m# test_common\u001B[39;00m\n\u001B[1;32m--> 370\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mestimator_checks\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _construct_instance\n\u001B[0;32m    372\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtype_of_target\u001B[39m(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m, raise_unknown\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    373\u001B[0m         \u001B[38;5;66;03m# fix for raise_unknown which is introduced in scikit-learn 1.6\u001B[39;00m\n\u001B[0;32m    374\u001B[0m         \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmulticlass\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m type_of_target\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\sklearn\\utils\\estimator_checks.py:29\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config_context\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     22\u001B[0m     ClusterMixin,\n\u001B[0;32m     23\u001B[0m     RegressorMixin,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     27\u001B[0m     is_regressor,\n\u001B[0;32m     28\u001B[0m )\n\u001B[1;32m---> 29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     30\u001B[0m     load_iris,\n\u001B[0;32m     31\u001B[0m     make_blobs,\n\u001B[0;32m     32\u001B[0m     make_classification,\n\u001B[0;32m     33\u001B[0m     make_multilabel_classification,\n\u001B[0;32m     34\u001B[0m     make_regression,\n\u001B[0;32m     35\u001B[0m )\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexceptions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataConversionWarning, NotFittedError, SkipTestWarning\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SelectFromModel, SelectKBest\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\sklearn\\datasets\\__init__.py:8\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03mThe :mod:`sklearn.datasets` module includes utilities to load datasets,\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mincluding methods to load and fetch popular reference datasets. It also\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03mfeatures some artificial data generators.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtextwrap\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_base\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      9\u001B[0m     clear_data_home,\n\u001B[0;32m     10\u001B[0m     get_data_home,\n\u001B[0;32m     11\u001B[0m     load_breast_cancer,\n\u001B[0;32m     12\u001B[0m     load_diabetes,\n\u001B[0;32m     13\u001B[0m     load_digits,\n\u001B[0;32m     14\u001B[0m     load_files,\n\u001B[0;32m     15\u001B[0m     load_iris,\n\u001B[0;32m     16\u001B[0m     load_linnerud,\n\u001B[0;32m     17\u001B[0m     load_sample_image,\n\u001B[0;32m     18\u001B[0m     load_sample_images,\n\u001B[0;32m     19\u001B[0m     load_wine,\n\u001B[0;32m     20\u001B[0m )\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_california_housing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m fetch_california_housing\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_covtype\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m fetch_covtype\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\sklearn\\datasets\\_base.py:25\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m scale\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Bunch, check_pandas_support, check_random_state\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_param_validation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Interval, StrOptions, validate_params\n\u001B[0;32m     28\u001B[0m DATA_MODULE \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msklearn.datasets.data\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'check_pandas_support' from 'sklearn.utils' (D:\\PyThon\\Lib\\site-packages\\sklearn\\utils\\__init__.py)"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # Column Transformer\n",
    "# X_train_trans = coltrans.fit_transform(X_train)\n",
    "# X_test_trans = coltrans.transform(X_test)"
   ],
   "id": "94521bace8955d71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:53:15.958176Z",
     "start_time": "2025-02-13T12:53:15.928491Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in less[:-1]:\n",
    "    test[i] = train[i].astype('category')\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# Define the new order of categories\n",
    "new_categories = ['< 1 Year', '1-2 Year', '> 2 Years']\n",
    "\n",
    "# Create a new CategoricalDtype with the desired order\n",
    "new_dtype = CategoricalDtype(categories=new_categories, ordered=True)\n",
    "\n",
    "# Update the 'Vehicle_Age' column with the new dtype\n",
    "test['Vehicle_Age'] = test['Vehicle_Age'].astype(new_dtype)\n",
    "test['age_bins'] = pd.cut(test['Age'], bins=7)\n",
    "test['Age_Type'] = test['age_bins'].cat.codes\n",
    "test['Age_x_Vehicle_Age'] = test['Age_Type'] * test['Vehicle_Age'].cat.codes\n",
    "test['Age_x_Vehicle_Damage'] = test['Age_Type'] * test['Vehicle_Damage'].cat.codes\n",
    "test['Age_x_Previously_Insured'] = test['Age_Type'] * test['Previously_Insured'].cat.codes\n",
    "test.drop(['id','age_bins'],axis=1,inplace=True)\n",
    "\n",
    "# # Column Transformer\n",
    "# test_trans = coltrans.transform(test)"
   ],
   "id": "32619d9f88a64608",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:53:29.534523Z",
     "start_time": "2025-02-13T12:53:29.207002Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder, RobustScaler, StandardScaler\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import clone\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "import gc"
   ],
   "id": "e4f0800f52b41f0a",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompose\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ColumnTransformer\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MinMaxScaler, OneHotEncoder, OrdinalEncoder, RobustScaler, StandardScaler\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscikeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mwrappers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KerasClassifier\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpipeline\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m make_pipeline\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m clone\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\scikeras\\__init__.py:9\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mimportlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetadata\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mimportlib_metadata\u001B[39;00m\n\u001B[0;32m      7\u001B[0m __version__ \u001B[38;5;241m=\u001B[39m importlib_metadata\u001B[38;5;241m.\u001B[39mversion(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscikeras\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_keras\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscikeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _saving_utils\n\u001B[0;32m     13\u001B[0m _keras\u001B[38;5;241m.\u001B[39mModel\u001B[38;5;241m.\u001B[39m__reduce__ \u001B[38;5;241m=\u001B[39m _saving_utils\u001B[38;5;241m.\u001B[39mpack_keras_model\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# DO NOT EDIT. Generated by api_gen.sh\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DTypePolicy\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FloatDTypePolicy\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Function\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\api\\__init__.py:8\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m activations\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m applications\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\api\\activations\\__init__.py:7\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deserialize\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m serialize\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\src\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m activations\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m applications\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\src\\activations\\__init__.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtypes\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m celu\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m elu\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m exponential\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\src\\activations\\activations.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ops\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\src\\backend\\__init__.py:10\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m result_type\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras_tensor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KerasTensor\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras_tensor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m any_symbolic_tensors\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\src\\backend\\common\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend_utils\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m result_type\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvariables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutocastScope\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvariables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Variable \u001B[38;5;28;01mas\u001B[39;00m KerasVariable\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\src\\backend\\common\\dtypes.py:5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvariables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m standardize_dtype\n\u001B[0;32m      7\u001B[0m BOOL_TYPES \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbool\u001B[39m\u001B[38;5;124m\"\u001B[39m,)\n\u001B[0;32m      8\u001B[0m INT_TYPES \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muint8\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muint16\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mint64\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     17\u001B[0m )\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py:11\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstateless_scope\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_stateless_scope\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstateless_scope\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m in_stateless_scope\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensorflow \u001B[38;5;28;01mas\u001B[39;00m tf\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnaming\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m auto_name\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mVariable\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\src\\utils\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio_dataset_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m audio_dataset_from_directory\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m split_dataset\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfile_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_file\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\src\\utils\\audio_dataset_utils.py:4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dataset_utils\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensorflow \u001B[38;5;28;01mas\u001B[39;00m tf\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensorflow_io \u001B[38;5;28;01mas\u001B[39;00m tfio\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\src\\utils\\dataset_utils.py:9\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmultiprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpool\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ThreadPool\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tree\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m io_utils\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\src\\tree\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m assert_same_paths\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m assert_same_structure\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m flatten\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\src\\tree\\tree_api.py:8\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m optree\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m optree\u001B[38;5;241m.\u001B[39mavailable:\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m optree_impl \u001B[38;5;28;01mas\u001B[39;00m tree_impl\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m dmtree\u001B[38;5;241m.\u001B[39mavailable:\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dmtree_impl \u001B[38;5;28;01mas\u001B[39;00m tree_impl\n",
      "File \u001B[1;32mD:\\PyThon\\Lib\\site-packages\\keras\\src\\tree\\optree_impl.py:13\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Register backend-specific node classes\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensorflow\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 13\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrackable\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_structures\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ListWrapper\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrackable\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_structures\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _DictWrapper\n\u001B[0;32m     16\u001B[0m     optree\u001B[38;5;241m.\u001B[39mregister_pytree_node(\n\u001B[0;32m     17\u001B[0m         ListWrapper,\n\u001B[0;32m     18\u001B[0m         \u001B[38;5;28;01mlambda\u001B[39;00m x: (x, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m     19\u001B[0m         \u001B[38;5;28;01mlambda\u001B[39;00m metadata, children: ListWrapper(\u001B[38;5;28mlist\u001B[39m(children)),\n\u001B[0;32m     20\u001B[0m         namespace\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     21\u001B[0m     )\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:53:49.678227Z",
     "start_time": "2025-02-13T12:53:49.674539Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "TARGET = 'Response'\n",
    "N_FOLDS = 5\n",
    "SEED = 42\n",
    "\n",
    "N_EPOCHS = 30\n",
    "LEARNING_RATE = 0.005\n",
    "BATCH_SIZE = 2048\n",
    "EVAL_BATCH_SIZE = 65536"
   ],
   "id": "8d29427a7bd4f60e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:58:43.518618Z",
     "start_time": "2025-02-13T12:58:43.510052Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, n_folds=N_FOLDS):\n",
    "        self.model = model\n",
    "        self.n_folds = n_folds\n",
    "\n",
    "    def fit_predict(self, X, y, X_test):\n",
    "        print(f'Training {self.model.__class__.__name__}\\n')\n",
    "        \n",
    "        scores = []        \n",
    "        oof_pred_probs = np.zeros((X.shape[0], len(np.unique(y))))\n",
    "        test_pred_probs = np.zeros((X_test.shape[0], len(np.unique(y))))\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=self.n_folds, random_state=SEED, shuffle=True)\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            \n",
    "            model = clone(self.model)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_probs = model.predict_proba(X_val)\n",
    "            oof_pred_probs[val_idx] = y_pred_probs            \n",
    "            score = roc_auc_score(y_val, y_pred_probs[:, 1])\n",
    "            scores.append(score)\n",
    "            \n",
    "            temp_test_pred_probs = model.predict_proba(X_test)\n",
    "            test_pred_probs += temp_test_pred_probs / self.n_folds\n",
    "            \n",
    "            print(f'\\n--- Fold {fold_idx + 1} - AUC: {score:.5f}\\n\\n')\n",
    "            \n",
    "            del model, X_train, y_train, X_val, y_val, y_pred_probs, temp_test_pred_probs\n",
    "            gc.collect()\n",
    "            \n",
    "        self._save_pred_probs(oof_pred_probs, np.mean(scores), 'oof')\n",
    "        self._save_pred_probs(test_pred_probs, np.mean(scores), 'test')\n",
    "        self._save_submission(test_pred_probs, np.mean(scores))\n",
    "        \n",
    "        print(f'------ Average AUC:      {np.mean(scores):.5f} ± {np.std(scores):.5f}\\n\\n')\n",
    "        \n",
    "        return oof_pred_probs, scores\n",
    "        \n",
    "    def _save_pred_probs(self, pred_probs, cv_score, name):\n",
    "        model_name = self.model.__class__.__name__.lower().replace('classifier', '')\n",
    "        with open(f'{model_name}_{name}_pred_probs_{cv_score:.5f}.pkl', 'wb') as f:\n",
    "            pickle.dump(pred_probs, f)\n",
    "    \n",
    "    def _save_submission(self, test_pred_probs, score):\n",
    "        name = self.model.__class__.__name__.lower().replace('classifier', '')\n",
    "        sub = pd.read_csv('/kaggle/input/playground-series-s4e7/sample_submission.csv')\n",
    "        sub['id'] = sub['id']\n",
    "        sub[TARGET] = test_pred_probs[:, 1]\n",
    "        # Referencee https://www.kaggle.com/code/paddykb/a-glitch-in-the-insurance-matrix\n",
    "        INPUT_DIR = Path('data/bx/op/com')\n",
    "        train_data = pd.read_csv(INPUT_DIR / 'train.csv')\n",
    "        test_data = pd.read_csv(INPUT_DIR / 'test.csv')\n",
    "        orig_data = pd.read_csv(r'D:\\mmmm\\pycharmM\\apr17\\data\\bx\\op\\com\\train.csv')\n",
    "        features = sorted(set(test_data.columns) - set(['id']))\n",
    "        train_data.merge(orig_data, on=features).filter(['Response_x', 'Response_y']).value_counts().reset_index()\n",
    "        override_sub = test_data.merge(orig_data.drop(columns=['id']), on=features).assign(override=lambda x: np.where(x['Response'] == 0, 1, 0)).filter(['id', 'override']).groupby(['id'], as_index=False).agg(override=('override', 'mean'))\n",
    "        sub.merge(override_sub, how='outer').assign(Response=lambda x: np.where(x['override'].isna(), x['Response'], x['override'])).filter(['id', 'Response']).to_csv(f'sub_{name}_{score:.5f}.csv', index=False)"
   ],
   "id": "6b3af39870dc22b2",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T12:59:56.879630Z",
     "start_time": "2025-02-13T12:59:56.864140Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(), ['Gender', 'Vehicle_Damage']),\n",
    "            ('minmax', MinMaxScaler(), ['Age', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Policy_Sales_Channel', 'Vintage']),\n",
    "            ('ordinal', OrdinalEncoder(categories=[['< 1 Year', '1-2 Year', '> 2 Years']]), ['Vehicle_Age']),\n",
    "            ('robust', RobustScaler(), ['Annual_Premium']),\n",
    "            ('standard', StandardScaler(), ['Age_Type', 'Age_x_Vehicle_Age', 'Age_x_Vehicle_Damage', 'Age_x_Previously_Insured'])\n",
    "        ],\n",
    "        remainder='passthrough'  # Keeps columns not specified in transformers\n",
    "    )\n",
    ")\n",
    "\n",
    "X = pipeline.fit_transform(X, y)\n",
    "X_test = pipeline.transform(test)\n",
    "\n",
    "del train, test, pipeline\n",
    "gc.collect()"
   ],
   "id": "a67b7ea9aaa4d353",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m \u001B[43mmake_pipeline\u001B[49m(\n\u001B[0;32m      2\u001B[0m     ColumnTransformer(\n\u001B[0;32m      3\u001B[0m         transformers\u001B[38;5;241m=\u001B[39m[\n\u001B[0;32m      4\u001B[0m             (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcat\u001B[39m\u001B[38;5;124m'\u001B[39m, OneHotEncoder(), [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGender\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVehicle_Damage\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[0;32m      5\u001B[0m             (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mminmax\u001B[39m\u001B[38;5;124m'\u001B[39m, MinMaxScaler(), [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAge\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDriving_License\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRegion_Code\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPreviously_Insured\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPolicy_Sales_Channel\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVintage\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[0;32m      6\u001B[0m             (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mordinal\u001B[39m\u001B[38;5;124m'\u001B[39m, OrdinalEncoder(categories\u001B[38;5;241m=\u001B[39m[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m< 1 Year\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1-2 Year\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m> 2 Years\u001B[39m\u001B[38;5;124m'\u001B[39m]]), [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVehicle_Age\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[0;32m      7\u001B[0m             (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrobust\u001B[39m\u001B[38;5;124m'\u001B[39m, RobustScaler(), [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAnnual_Premium\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[0;32m      8\u001B[0m             (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstandard\u001B[39m\u001B[38;5;124m'\u001B[39m, StandardScaler(), [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAge_Type\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAge_x_Vehicle_Age\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAge_x_Vehicle_Damage\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAge_x_Previously_Insured\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      9\u001B[0m         ],\n\u001B[0;32m     10\u001B[0m         remainder\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m'\u001B[39m  \u001B[38;5;66;03m# Keeps columns not specified in transformers\u001B[39;00m\n\u001B[0;32m     11\u001B[0m     )\n\u001B[0;32m     12\u001B[0m )\n\u001B[0;32m     14\u001B[0m X \u001B[38;5;241m=\u001B[39m pipeline\u001B[38;5;241m.\u001B[39mfit_transform(X, y)\n\u001B[0;32m     15\u001B[0m X_test \u001B[38;5;241m=\u001B[39m pipeline\u001B[38;5;241m.\u001B[39mtransform(test)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'make_pipeline' is not defined"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_model(meta):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(meta[\"X_shape_\"][1:]))\n",
    "    model.add(keras.layers.Dense(52, kernel_initializer='truncated_normal', activation='silu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dense(660, kernel_initializer='truncated_normal', activation='silu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dense(508, kernel_initializer='truncated_normal', activation='silu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dense(1, kernel_initializer='truncated_normal', activation='sigmoid'))\n",
    "    return model"
   ],
   "id": "e6ba67ad4b8803b6"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = KerasClassifier(\n",
    "    get_model,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[keras.metrics.AUC(name='auc')],\n",
    "    optimizer=keras.optimizers.AdamW(learning_rate=LEARNING_RATE),\n",
    "    validation_split=0.1,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_batch_size=EVAL_BATCH_SIZE,\n",
    "    epochs=N_EPOCHS, \n",
    "    verbose=0,\n",
    "    callbacks=[\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_auc', patience=3, factor=0.3),\n",
    "        keras.callbacks.EarlyStopping(monitor='val_auc', patience=3)\n",
    "    ]\n",
    ")"
   ],
   "id": "501fd634f4f1b8be"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "trainer = Trainer(model)\n",
    "oof_pred_probs, scores = trainer.fit_predict(X, y, X_test)"
   ],
   "id": "cb8e8dbec9743e94"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 7))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y, oof_pred_probs[:, 1])\n",
    "axes[0].plot(fpr, tpr, label=f'AUC: {np.mean(scores):.5f}', color='#651FFF')\n",
    "axes[0].plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "axes[0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "y_pred = oof_pred_probs.argmax(axis=1)\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt=',', \n",
    "    ax=axes[1], \n",
    "    cbar=False,\n",
    "    cmap=sns.light_palette('#651FFF', reverse=False, as_cmap=True), \n",
    ")\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "axes[1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "7f962329b3dae78"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "a258c063068aa5e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}